<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Dreamy Interactive Spectrograph Music Visualizer</title>
    <link rel="stylesheet" href="assets/css/base.css" />
    <style>
      body {
        background-color: black;
        touch-action: none;
        display: flex;
        justify-content: center;
        align-items: center;
        font-family: Arial, sans-serif;
      }
      #error-message {
        position: absolute;
        top: 20px;
        left: 20px;
        color: #ff0000;
        background: rgba(0, 0, 0, 0.7);
        padding: 10px;
        border-radius: 5px;
        z-index: 10;
      }
    </style>
  </head>
  <body>
    <a href="index.html" class="home-link">Back to Library</a>
    <div id="error-message" style="display: none"></div>
    <canvas id="glCanvas"></canvas>
    <script type="module">
      import {
        initAudio,
        getFrequencyData,
      } from './assets/js/utils/audio-handler.ts';
      import { setupCanvasResize } from './assets/js/utils/canvas-resize.ts';
      import { initHints } from './assets/ui/hints.ts';
      import { initFunControls } from './assets/ui/fun-controls.ts';
      import { createSymphFunAdapter } from './assets/symph/fun-adapter.ts';
      const canvas = document.getElementById('glCanvas');
      const gl = canvas.getContext('webgl');
      const ctx2d = canvas.getContext('2d');
      const errorEl = document.getElementById('error-message');

      function displayError(message) {
        if (errorEl) {
          errorEl.textContent = message;
          errorEl.style.display = 'block';
        }
      }

      initHints({
        id: 'symph-visualizer',
        tips: [
          'Play music or tap to trigger sparkles.',
          'Switch to Party Mode for bigger motion.',
          'Drag across the canvas to nudge the spectrograph ripples.',
        ],
      });

      function hideError() {
        if (errorEl) {
          errorEl.style.display = 'none';
          errorEl.textContent = '';
        }
      }

      if (!gl) {
        displayError(
          'Unable to initialize WebGL. Your browser may not support it.'
        );
        throw new Error('WebGL not supported');
      }

      const vertexShaderSource = `
            attribute vec4 a_position;
            void main() {
                gl_Position = a_position;
            }
        `;

      const fragmentShaderSource = `
            precision highp float;
            uniform float u_time;
            uniform vec2 u_resolution;
            uniform float u_audioData;
            uniform vec3 u_colorOffset;
            uniform vec2 u_touch;
            
            vec3 dreamyGradient(vec2 uv, float timeOffset) {
                vec3 color = vec3(0.4 + 0.4 * sin(uv.x * 10.0 + u_audioData * 6.0 + timeOffset),
                                  0.4 + 0.4 * cos(uv.y * 10.0 + u_audioData * 6.0 + timeOffset),
                                  0.5 + 0.4 * sin((uv.x + uv.y) * 8.0 + u_audioData * 6.0 + timeOffset));
                return color + u_colorOffset * 0.7;
            }
            
            void main() {
                vec2 uv = gl_FragCoord.xy / u_resolution.xy;
                uv -= 0.5;
                uv *= 2.0;
                
                float dist = distance(uv, u_touch);
                float ripple = sin(dist * 15.0 - u_time * 3.0) * 0.15;
                float bloom = 0.3 / (dist * dist + 0.25);
                uv += ripple;
                
                vec3 color = dreamyGradient(uv, u_time * 0.6) * u_audioData;
                color += vec3(0.4 + 0.4 * sin(u_time * 0.4 + u_audioData * 2.0), 
                              0.4 + 0.4 * cos(u_time * 0.5 + u_audioData * 3.0), 
                              0.5 + 0.4 * sin(u_time * 0.6 + u_audioData * 1.5));
                color += bloom * 0.6;
                
                gl_FragColor = vec4(color, 1.0);
            }
        `;

      function createShader(gl, type, source) {
        const shader = gl.createShader(type);
        gl.shaderSource(shader, source);
        gl.compileShader(shader);
        if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
          console.error(gl.getShaderInfoLog(shader));
          gl.deleteShader(shader);
          return null;
        }
        return shader;
      }

      const vertexShader = createShader(
        gl,
        gl.VERTEX_SHADER,
        vertexShaderSource
      );
      const fragmentShader = createShader(
        gl,
        gl.FRAGMENT_SHADER,
        fragmentShaderSource
      );

      const program = gl.createProgram();
      gl.attachShader(program, vertexShader);
      gl.attachShader(program, fragmentShader);
      gl.linkProgram(program);
      if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
        console.error(gl.getProgramInfoLog(program));
        gl.deleteProgram(program);
        throw new Error('Program failed to link');
      }

      gl.useProgram(program);

      const positionBuffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
      const positions = [
        -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0,
      ];
      gl.bufferData(
        gl.ARRAY_BUFFER,
        new Float32Array(positions),
        gl.STATIC_DRAW
      );

      const positionAttributeLocation = gl.getAttribLocation(
        program,
        'a_position'
      );
      gl.enableVertexAttribArray(positionAttributeLocation);
      gl.vertexAttribPointer(
        positionAttributeLocation,
        2,
        gl.FLOAT,
        false,
        0,
        0
      );

      const resolutionUniformLocation = gl.getUniformLocation(
        program,
        'u_resolution'
      );
      const timeUniformLocation = gl.getUniformLocation(program, 'u_time');
      const audioDataUniformLocation = gl.getUniformLocation(
        program,
        'u_audioData'
      );
      const colorOffsetUniformLocation = gl.getUniformLocation(
        program,
        'u_colorOffset'
      );
      const touchUniformLocation = gl.getUniformLocation(program, 'u_touch');

      const disposeResize = setupCanvasResize(canvas, gl, {
        maxPixelRatio: 2,
        onResize: ({ width, height }) => {
          gl.uniform2f(resolutionUniformLocation, width, height);
        },
      });

      const adapter = createSymphFunAdapter();
      const funControls = initFunControls({
        paletteOptions: adapter.paletteOptions,
        onPaletteChange: (palette, colors) => {
          adapter.setPalette(palette, colors);
          colorOffset = [...adapter.paletteAccent];
          gradientStops = colors;
        },
        onMotionChange: (intensity, mode) => adapter.setMotion(intensity, mode),
        onAudioToggle: (enabled) => adapter.setAudioReactive(enabled),
      });

      let gradientStops = adapter.paletteOptions.bright;
      let time = 0.0;
      let audioData = adapter.transformAudioValue(0);
      let colorOffset = [...adapter.paletteAccent];
      let touchPoint = [0.0, 0.0];
      let analyser;

      async function setupAudio() {
        try {
          const { analyser: a } = await initAudio();
          analyser = a;
          hideError();
          getAudioData();
          funControls.setAudioAvailable(true);
        } catch (err) {
          displayError(
            'Microphone access is unavailable. Visuals will run without audio reactivity.'
          );
          funControls.setAudioAvailable(false);
          audioData = adapter.transformAudioValue(0);
          console.error('Error capturing audio: ', err);
        }
      }

      function getAudioData() {
        requestAnimationFrame(getAudioData);
        if (analyser) {
          const dataArray = getFrequencyData(analyser);
          const average =
            dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
          audioData = adapter.transformAudioValue(average);
          updateSpectrograph(dataArray);
        }
      }

      function updateSpectrograph(dataArray) {
        ctx2d.clearRect(0, 0, canvas.width, canvas.height);
        const gradient = ctx2d.createLinearGradient(
          0,
          0,
          canvas.width,
          canvas.height
        );
        gradient.addColorStop(0, gradientStops[0]);
        gradient.addColorStop(0.5, gradientStops[1]);
        gradient.addColorStop(1, gradientStops[2]);
        ctx2d.fillStyle = gradient;
        const barWidth = (canvas.width / dataArray.length) * 1.5;
        let barHeight;
        let x = 0;

        for (let i = 0; i < dataArray.length; i++) {
          barHeight = dataArray[i] / 2;
          ctx2d.fillRect(x, canvas.height - barHeight, barWidth, barHeight);
          x += barWidth + 1;
        }
      }

      setupAudio();

      function render() {
        time += 0.02;
        gl.uniform1f(timeUniformLocation, time);
        gl.uniform1f(audioDataUniformLocation, audioData);
        gl.uniform3fv(colorOffsetUniformLocation, colorOffset);
        gl.uniform2fv(touchUniformLocation, touchPoint);

        gl.clear(gl.COLOR_BUFFER_BIT);
        gl.drawArrays(gl.TRIANGLES, 0, 6);

        requestAnimationFrame(render);
      }

      requestAnimationFrame(render);

      // Handle pointer input
      canvas.addEventListener('pointermove', (event) => {
        const x = (event.clientX / canvas.clientWidth) * 2.0 - 1.0;
        const y = -(event.clientY / canvas.clientHeight) * 2.0 + 1.0;
        touchPoint = [x, y];
      });
      window.addEventListener('pagehide', disposeResize);
    </script>
  </body>
</html>
