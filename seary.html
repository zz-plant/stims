<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, user-scalable=no"
    />
    <title>Trippy Synesthetic Visualizer with WebGL</title>
    <link rel="stylesheet" href="assets/css/base.css" />
    <style>
      body,
      html {
        height: 100%;
        background-color: #000000; /* OLED black */
      }
      canvas {
        width: 100vw;
        height: 100vh;
      }
    </style>
  </head>
  <body>
    <a href="index.html" class="home-link">Back to Library</a>
    <canvas id="gpuCanvas"></canvas>
    <div id="error-message" style="display: none"></div>
    <select id="audioSelect">
      <option value="mic">Microphone</option>
      <option value="device">Device Audio</option>
    </select>
    <script type="module">
      import {
        initAudio,
        getFrequencyData,
      } from './assets/js/utils/audio-handler.ts';
      // Fallback to WebGL
      const canvas = document.getElementById('gpuCanvas');
      function displayError(message) {
        const el = document.getElementById("error-message");
        if (el) {
          el.innerText = message;
          el.style.display = "block";
        }
      }

      const gl =
        canvas.getContext('webgl') || canvas.getContext('experimental-webgl');

      if (!gl) {
        console.error('WebGL not supported');
        throw new Error('WebGL not supported');
      }

      // Resize canvas
      function resizeCanvas() {
        canvas.width = window.innerWidth;
        canvas.height = window.innerHeight;
        gl.viewport(0, 0, canvas.width, canvas.height);
      }
      window.addEventListener('resize', resizeCanvas);
      resizeCanvas();

      // Compile shader
      function compileShader(source, type) {
        const shader = gl.createShader(type);
        gl.shaderSource(shader, source);
        gl.compileShader(shader);
        if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
          console.error(
            'Shader compile failed: ' + gl.getShaderInfoLog(shader)
          );
          gl.deleteShader(shader);
          throw new Error('Shader compile error');
        }
        return shader;
      }

      // Vertex shader source
      const vertexShaderSource = `
            attribute vec2 a_position;
            varying vec2 v_uv;
            void main() {
                v_uv = a_position * 0.5 + 0.5;
                gl_Position = vec4(a_position, 0.0, 1.0);
            }
        `;

      // Fragment shader source
      const fragmentShaderSource = `
            precision mediump float;
            uniform float u_time;
            uniform float u_low_freq;
            uniform float u_mid_freq;
            uniform float u_high_freq;
            uniform vec2 u_touch0;
            uniform vec2 u_touch1;
            uniform vec3 u_orientation;
            varying vec2 v_uv;
            
            float noise(vec2 p) {
                return sin(p.x * 12.9898 + p.y * 78.233) * 43758.5453 - floor(sin(p.x * 12.9898 + p.y * 78.233) * 43758.5453);
            }

            void main() {
                vec2 uv = v_uv - 0.5;
                float dist = length(uv);
                float angle = atan(uv.y, uv.x);

                // Background color shifting and dynamic gradients
                vec3 baseColor = vec3(
                    0.5 + 0.5 * sin(u_time + angle + u_low_freq * 5.0),
                    0.5 + 0.5 * cos(u_time + angle * 2.0 + u_mid_freq * 3.0),
                    0.5 + 0.5 * sin(u_time * 0.5 + angle * 3.0 + u_high_freq * 7.0)
                );

                // Low frequency pulsing waves
                float lowWave = 0.5 + 0.5 * sin(15.0 * dist - u_time + angle * 3.0) * (u_low_freq + 0.3);
                vec3 lowColor = vec3(lowWave * 0.5, lowWave * 0.3, lowWave);

                // Mid frequency oscillations with noise distortion
                float midOscillation = 0.5 + 0.5 * cos(20.0 * dist - u_time * 1.5 + angle * 4.0) * (u_mid_freq + 0.4);
                midOscillation += noise(uv * 10.0) * 0.2 * u_mid_freq;
                vec3 midColor = vec3(midOscillation * 0.3, midOscillation, midOscillation * 0.6);

                // High frequency sparks with strobe effect
                float highSpark = 0.5 + 0.5 * sin(25.0 * dist - u_time * 2.0 + angle * 6.0) * (u_high_freq + 0.5);
                highSpark += step(0.9, fract(sin(u_time * 10.0) * 43758.5453)) * 0.3 * u_high_freq;
                vec3 highColor = vec3(highSpark, highSpark * 0.5, highSpark * 0.2);

                // Blend low, mid, and high colors together for synesthetic experience
                vec3 color = baseColor + lowColor + midColor + highColor;

                // Add ripple effects from multi-touch interactions
                float touchEffect0 = 0.0;
                float touchEffect1 = 0.0;
                if (length(u_touch0) > 0.0) {
                    touchEffect0 = 0.2 / length(uv - (u_touch0 - 0.5));
                }
                if (length(u_touch1) > 0.0) {
                    touchEffect1 = 0.2 / length(uv - (u_touch1 - 0.5));
                }
                color += vec3(touchEffect0 + touchEffect1);

                // Orientation-based distortion to make visuals more fluid and trippy
                float orientationEffect = sin(u_orientation.x * uv.x * 10.0 + u_time) * 0.1 * u_orientation.y;
                uv += vec2(orientationEffect, orientationEffect);

                // Kaleidoscope-like radial gradient with more vivid effects
                float radialGradient = smoothstep(0.6, 0.0, dist) * (1.0 + sin(u_time * 5.0 + dist * 15.0) * 0.1);
                color *= radialGradient;

                // Add more glow and blur for a dreamy, synesthetic feel
                float glow = exp(-10.0 * dist) * (u_low_freq + u_mid_freq + u_high_freq);
                color += vec3(glow * 0.4, glow * 0.6, glow * 0.8);

                gl_FragColor = vec4(color, 1.0);
            }
        `;

      // Create and link program
      const vertexShader = compileShader(vertexShaderSource, gl.VERTEX_SHADER);
      const fragmentShader = compileShader(
        fragmentShaderSource,
        gl.FRAGMENT_SHADER
      );
      const program = gl.createProgram();
      gl.attachShader(program, vertexShader);
      gl.attachShader(program, fragmentShader);
      gl.linkProgram(program);

      if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
        console.error('Program link failed: ' + gl.getProgramInfoLog(program));
        throw new Error('Program link error');
      }
      gl.useProgram(program);

      // Set up geometry
      const positionBuffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
      gl.bufferData(
        gl.ARRAY_BUFFER,
        new Float32Array([-1, -1, 1, -1, -1, 1, -1, 1, 1, -1, 1, 1]),
        gl.STATIC_DRAW
      );

      const positionLocation = gl.getAttribLocation(program, 'a_position');
      gl.enableVertexAttribArray(positionLocation);
      gl.vertexAttribPointer(positionLocation, 2, gl.FLOAT, false, 0, 0);

      // Set up uniforms
      const timeLocation = gl.getUniformLocation(program, 'u_time');
      const lowFreqLocation = gl.getUniformLocation(program, 'u_low_freq');
      const midFreqLocation = gl.getUniformLocation(program, 'u_mid_freq');
      const highFreqLocation = gl.getUniformLocation(program, 'u_high_freq');
      const touch0Location = gl.getUniformLocation(program, 'u_touch0');
      const touch1Location = gl.getUniformLocation(program, 'u_touch1');
      const orientationLocation = gl.getUniformLocation(
        program,
        'u_orientation'
      );

      // Audio setup for beat detection and frequency analysis
      let audioContext, analyser, source;
      let bufferLength, dataArray;
      const audioSelect = document.getElementById('audioSelect');

      audioSelect.addEventListener('change', initializeAudio);
      initializeAudio();

      function initializeAudio() {
        if (audioContext) {
          audioContext.close();
        }

        navigator.mediaDevices
          .getUserMedia({ audio: true })
          .then((stream) => {
            audioContext = new (window.AudioContext ||
              window.webkitAudioContext)();
            if (audioSelect.value === 'mic') {
              initAudio().then(({ analyser: a, dataArray: d }) => {
                analyser = a;
                source = audioContext.createMediaStreamSource(stream);
                source.connect(analyser);
                startProcessing(d);
              }).catch((err) => {
                console.error("Error capturing audio: ", err);
                displayError("Microphone access is required for the visualization to work. Please allow microphone access.");
              });
            } else {
              // Use the audio context's `createMediaElementSource` to capture device audio
              const audioElement = new Audio();
              audioElement.crossOrigin = 'anonymous';
              source = audioContext.createMediaElementSource(audioElement);
              source.connect(audioContext.destination); // To allow playback
              audioElement.play();
            }
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 256;
            source.connect(analyser);
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            startProcessing(dataArray);

            let lastVibrateTime = 0;

            function vibrateBasedOnAudio(lowFreq, midFreq, highFreq) {
              const intensity = Math.max(lowFreq, midFreq, highFreq);
              const currentTime = Date.now();

              // Vibrate only during significant visual events and not too frequently
              if (intensity > 0.7 && currentTime - lastVibrateTime > 500) {
                if (navigator.vibrate) {
                  navigator.vibrate([intensity * 100, 50, intensity * 100]);
                }
                lastVibrateTime = currentTime;
              }
            }

            function vibrateBasedOnVisuals(lowFreq, midFreq, highFreq, dist) {
              const vibrateIntensity =
                Math.max(lowFreq, midFreq, highFreq) * (1.0 - dist);
              if (navigator.vibrate && vibrateIntensity > 0.5) {
                navigator.vibrate([
                  Math.floor(vibrateIntensity * 200),
                  50,
                  Math.floor(vibrateIntensity * 200),
                ]);
              }
            }

            // Device orientation-based distortion
            let orientation = { alpha: 0, beta: 0, gamma: 0 };
            window.addEventListener('deviceorientation', (event) => {
              orientation.alpha = event.alpha;
              orientation.beta = event.beta;
              orientation.gamma = event.gamma;
            });

            // Pointer-based multi-touch effects
            let touches = [
              { x: 0.0, y: 0.0 },
              { x: 0.0, y: 0.0 },
            ];
            const activePointers = new Map();

            canvas.addEventListener('pointerdown', (event) => {
              updatePointer(event);
              event.preventDefault();
            });

            canvas.addEventListener('pointermove', (event) => {
              updatePointer(event);
              event.preventDefault();
            });

            canvas.addEventListener('pointerup', (event) => {
              activePointers.delete(event.pointerId);
              refreshTouches();
            });

            function updatePointer(event) {
              activePointers.set(event.pointerId, {
                x: event.clientX,
                y: event.clientY,
              });
              refreshTouches();
            }

            function refreshTouches() {
              const values = Array.from(activePointers.values());
              for (let i = 0; i < touches.length; i++) {
                if (i < values.length) {
                  const p = values[i];
                  touches[i].x = (p.x / window.innerWidth) * 2.0 - 1.0;
                  touches[i].y = 1.0 - (p.y / window.innerHeight) * 2.0;
                } else {
                  touches[i].x = 0.0;
                  touches[i].y = 0.0;
                }
              }
            }

            function startProcessing(arr) {
              dataArray = arr;
              bufferLength = analyser.frequencyBinCount;
              updateAudioData();
            }

            function updateAudioData() {
              dataArray = getFrequencyData(analyser);
              const lowFreq =
                dataArray
                  .slice(0, bufferLength / 3)
                  .reduce((sum, value) => sum + value, 0) /
                (bufferLength / 3) /
                256.0;
              const midFreq =
                dataArray
                  .slice(bufferLength / 3, (2 * bufferLength) / 3)
                  .reduce((sum, value) => sum + value, 0) /
                (bufferLength / 3) /
                256.0;
              const highFreq =
                dataArray
                  .slice((2 * bufferLength) / 3, bufferLength)
                  .reduce((sum, value) => sum + value, 0) /
                (bufferLength / 3) /
                256.0;

              // Beat detection based on low frequency threshold
              if (lowFreq > 0.5) {
                canvas.style.transform = 'scale(1.1)';
                setTimeout(() => {
                  canvas.style.transform = 'scale(1)';
                }, 100);
              }

              gl.uniform1f(lowFreqLocation, lowFreq);
              gl.uniform1f(midFreqLocation, midFreq);
              gl.uniform1f(highFreqLocation, highFreq);
              gl.uniform3f(
                orientationLocation,
                orientation.alpha / 360.0,
                orientation.beta / 90.0,
                orientation.gamma / 90.0
              );

              gl.uniform2f(touch0Location, touches[0].x, touches[0].y);
              gl.uniform2f(touch1Location, touches[1].x, touches[1].y);

              vibrateBasedOnAudio(lowFreq, midFreq, highFreq);
              vibrateBasedOnVisuals(lowFreq, midFreq, highFreq, Math.random());

              requestAnimationFrame(updateAudioData);
            }
            updateAudioData();
          })
          .catch((err) => {
            console.error('Error accessing microphone: ' + err);
          });
      }

      // Render loop
      function render(time) {
        time *= 0.001; // Convert time to seconds

        // Set uniforms
        gl.uniform1f(timeLocation, time);

        // Draw
        gl.clearColor(0, 0, 0, 1);
        gl.clear(gl.COLOR_BUFFER_BIT);
        gl.drawArrays(gl.TRIANGLES, 0, 6);

        requestAnimationFrame(render);
      }
      requestAnimationFrame(render);
    </script>
  </body>
</html>
