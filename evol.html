<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, viewport-fit=cover"
    />
    <title>Evolutionary Weirdcore Visualizer</title>
    <link rel="stylesheet" href="assets/css/base.css" />
  </head>
  <body>
    <a href="index.html" class="home-link">Back to Library</a>
    <div id="error-message"></div>
    <canvas id="glCanvas" class="toy-canvas"></canvas>
    <div class="control-panel">
      <div class="control-panel__row">
        <label class="control-panel__text" for="fractalIntensity">
          <span class="control-panel__label">Fractal Intensity</span>
        </label>
        <input
          type="range"
          id="fractalIntensity"
          min="0.5"
          max="2.0"
          step="0.1"
          value="1.0"
        />
      </div>
    </div>
    <script type="module">
      import { initAudio, getFrequencyData } from './assets/js/utils/audio-handler.ts';
      import { setupCanvasResize } from './assets/js/utils/canvas-resize.ts';
      import { startToyAudio } from './assets/js/utils/start-audio.ts';
      const canvas = document.getElementById('glCanvas');
      const gl = canvas.getContext('webgl');
      const errorEl = document.getElementById('error-message');

      function displayError(message) {
        if (errorEl) {
          errorEl.textContent = message;
          errorEl.style.display = 'block';
        }
      }

      function hideError() {
        if (errorEl) {
          errorEl.style.display = 'none';
          errorEl.textContent = '';
        }
      }

      if (!gl) {
        displayError(
          'Unable to initialize WebGL. Your browser may not support it.'
        );
        throw new Error('WebGL not supported');
      }

      const vertexShaderSource = `
            attribute vec4 a_position;
            varying vec2 v_uv;
            void main() {
                v_uv = a_position.xy * 0.5 + 0.5;
                gl_Position = a_position;
            }
        `;

      const fragmentShaderSource = `
            precision highp float;
            uniform float u_time;
            uniform vec2 u_resolution;
            uniform float u_audioData;
            uniform float u_fractalIntensity;
            varying vec2 v_uv;

            float random(vec2 p) {
                return fract(sin(dot(p.xy, vec2(12.9898, 78.233))) * 43758.5453);
            }

            float noise(vec2 p) {
                vec2 i = floor(p);
                vec2 f = fract(p);
                float a = random(i);
                float b = random(i + vec2(1.0, 0.0));
                float c = random(i + vec2(0.0, 1.0));
                float d = random(i + vec2(1.0, 1.0));
                vec2 u = f * f * (3.0 - 2.0 * f);
                return mix(a, b, u.x) + (c - a) * u.y + (d - c) * u.x * u.y;
            }

            float fbm(vec2 p) {
                float total = 0.0;
                float amplitude = 1.0;
                for (int i = 0; i < 8; i++) {
                    total += noise(p) * amplitude;
                    p *= 2.0;
                    amplitude *= 0.5;
                }
                return total;
            }

            vec3 weirdcorePalette(float t, float audio) {
                vec3 a = vec3(0.5, 0.5, 0.5);
                vec3 b = vec3(0.5, 0.5, 0.5);
                vec3 c = vec3(1.0, 0.7, 0.4);
                vec3 d = vec3(0.0, 0.15, 0.2);
                return a + b * cos(6.28318 * (c * t + d + audio * 0.5));
            }

            void main() {
                vec2 uv = v_uv;
                vec2 pos = (gl_FragCoord.xy / u_resolution.xy) * 2.0 - 1.0;
                pos.x *= u_resolution.x / u_resolution.y;

                float audioEffect = u_audioData * 8.0;
                
                // Warped coordinates for surreal effect
                vec2 warpedUV = uv + vec2(
                    sin(uv.y * 10.0 + u_time + audioEffect) * 0.05,
                    cos(uv.x * 10.0 + u_time * 1.3) * 0.05
                );
                
                float distortion = fbm(warpedUV * u_fractalIntensity * 3.0 + audioEffect) * 0.6;
                float distortion2 = fbm(warpedUV * u_fractalIntensity * 1.5 - u_time * 0.5) * 0.4;
                
                // Enhanced glitch effects
                float glitch = step(0.92, random(uv * u_time * 3.0)) * 0.8;
                float scanline = sin(gl_FragCoord.y * 0.5 + u_time * 10.0) * 0.03;
                float vhsNoise = random(vec2(u_time * 0.1, gl_FragCoord.y * 0.01)) * 0.05;
                
                // Color shifts for weirdcore aesthetic
                float colorShift = sin(u_time * 0.5 + distortion * 5.0) * 0.5 + 0.5;
                vec3 color = weirdcorePalette(distortion + distortion2, u_audioData);
                
                // Add chromatic aberration
                float chromaOffset = (0.01 + u_audioData * 0.02);
                vec3 chromaColor;
                chromaColor.r = weirdcorePalette(distortion + chromaOffset, u_audioData).r;
                chromaColor.g = color.g;
                chromaColor.b = weirdcorePalette(distortion - chromaOffset, u_audioData).b;
                
                color = mix(color, chromaColor, 0.7);
                color += glitch * vec3(1.0, 0.0, 0.5);
                color += scanline;
                color += vhsNoise;
                
                // Vignette
                float vignette = 1.0 - length(pos) * 0.4;
                color *= vignette;
                
                gl_FragColor = vec4(color, 1.0);
            }
        `;

      function createShader(gl, type, source) {
        const shader = gl.createShader(type);
        gl.shaderSource(shader, source);
        gl.compileShader(shader);
        if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
          console.error(gl.getShaderInfoLog(shader));
          gl.deleteShader(shader);
          return null;
        }
        return shader;
      }

      const vertexShader = createShader(
        gl,
        gl.VERTEX_SHADER,
        vertexShaderSource
      );
      const fragmentShader = createShader(
        gl,
        gl.FRAGMENT_SHADER,
        fragmentShaderSource
      );

      const program = gl.createProgram();
      gl.attachShader(program, vertexShader);
      gl.attachShader(program, fragmentShader);
      gl.linkProgram(program);
      if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
        console.error(gl.getProgramInfoLog(program));
        gl.deleteProgram(program);
        throw new Error('Program failed to link');
      }

      gl.useProgram(program);

      const positionBuffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
      const positions = [
        -1.0, -1.0, 1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, -1.0, 1.0, 1.0,
      ];
      gl.bufferData(
        gl.ARRAY_BUFFER,
        new Float32Array(positions),
        gl.STATIC_DRAW
      );

      const positionAttributeLocation = gl.getAttribLocation(
        program,
        'a_position'
      );
      gl.enableVertexAttribArray(positionAttributeLocation);
      gl.vertexAttribPointer(
        positionAttributeLocation,
        2,
        gl.FLOAT,
        false,
        0,
        0
      );

      const resolutionUniformLocation = gl.getUniformLocation(
        program,
        'u_resolution'
      );
      const timeUniformLocation = gl.getUniformLocation(program, 'u_time');
      const audioDataUniformLocation = gl.getUniformLocation(
        program,
        'u_audioData'
      );
      const fractalIntensityLocation = gl.getUniformLocation(
        program,
        'u_fractalIntensity'
      );

      const disposeResize = setupCanvasResize(canvas, gl, {
        maxPixelRatio: 2,
        onResize: ({ width, height }) => {
          gl.uniform2f(resolutionUniformLocation, width, height);
        },
      });

      class CanvasToy {
        constructor(canvasEl) {
          this.canvas = canvasEl;
          this.analyser = null;
          this.audioCleanup = null;
          this.loopId = null;
          this.renderLoop = null;
          this.renderer = {
            setAnimationLoop: (loop) => {
              if (this.loopId) {
                cancelAnimationFrame(this.loopId);
              }

              this.renderLoop = loop;

              if (!loop) return;

              const tick = () => {
                this.renderLoop?.();
                this.loopId = requestAnimationFrame(tick);
              };

              tick();
            },
          };
        }

        async initAudio(options = {}) {
          const audio = await initAudio(options);
          this.analyser = audio.analyser;
          this.audioCleanup = audio.cleanup;
          return audio;
        }

        dispose() {
          if (this.loopId) {
            cancelAnimationFrame(this.loopId);
          }

          this.renderLoop = null;
          this.loopId = null;
          this.audioCleanup?.();
        }
      }

      const toy = new CanvasToy(canvas);

      let time = 0.0;
      let audioData = 0.0;
      let fractalIntensity = 1.0;

      document
        .getElementById('fractalIntensity')
        .addEventListener('input', (event) => {
          fractalIntensity = event.target.value;
        });

      function render(ctxAudio) {
        if (ctxAudio.analyser) {
          const dataArray = getFrequencyData(ctxAudio.analyser);
          const average =
            dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
          audioData = average / 128.0;
          hideError();
        } else {
          audioData = 0;
        }

        time += 0.02;
        gl.uniform1f(timeUniformLocation, time);
        gl.uniform1f(audioDataUniformLocation, audioData);
        gl.uniform1f(fractalIntensityLocation, fractalIntensity);

        gl.clear(gl.COLOR_BUFFER_BIT);
        gl.drawArrays(gl.TRIANGLES, 0, 6);
      }

      startToyAudio(toy, render, { fallbackToSynthetic: true })
        .then(() => hideError())
        .catch((err) => {
          console.error('Error capturing audio: ', err);
          displayError(
            'Microphone access is required for the visualization to work. Please allow microphone access.'
          );
          toy.renderer.setAnimationLoop(() => render({ toy, analyser: null }));
        });

      window.addEventListener('pagehide', () => {
        disposeResize();
        toy.dispose?.();
      });
    </script>
  </body>
</html>
