<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Evolutionary Weirdcore Visualizer</title>
    <link rel="stylesheet" href="assets/css/base.css">
    <style>
        body {
            background-color: #000000; /* OLED black */
        }
        canvas {
            width: 100vw;
            height: 100vh;
        }
        #controls {
            position: absolute;
            top: 10px;
            left: 10px;
            z-index: 10;
            background: rgba(0, 0, 0, 0.7);
            padding: 15px;
            border-radius: 8px;
        }
        #controls label {
            color: #ffffff;
            font-size: 14px;
            display: block;
            margin-bottom: 5px;
        }
    </style>
</head>
<body>
    <canvas id="glCanvas"></canvas>
    <div id="controls">
        <label>
            Fractal Intensity: 
            <input type="range" id="fractalIntensity" min="0.5" max="2.0" step="0.1" value="1.0">
        </label>
    </div>
    <script>
        const canvas = document.getElementById("glCanvas");
        const gl = canvas.getContext("webgl");

        if (!gl) {
            alert("Unable to initialize WebGL. Your browser may not support it.");
            throw new Error("WebGL not supported");
        }

        function resizeCanvas() {
            canvas.width = window.innerWidth;
            canvas.height = window.innerHeight;
            gl.viewport(0, 0, gl.drawingBufferWidth, gl.drawingBufferHeight);
        }
        window.addEventListener('resize', resizeCanvas);
        resizeCanvas();

        const vertexShaderSource = `
            attribute vec4 a_position;
            varying vec2 v_uv;
            void main() {
                v_uv = a_position.xy * 0.5 + 0.5;
                gl_Position = a_position;
            }
        `;
        
        const fragmentShaderSource = `
            precision highp float;
            uniform float u_time;
            uniform vec2 u_resolution;
            uniform float u_audioData;
            uniform float u_fractalIntensity;
            varying vec2 v_uv;

            float random(vec2 p) {
                return fract(sin(dot(p.xy, vec2(12.9898, 78.233))) * 43758.5453);
            }

            float noise(vec2 p) {
                vec2 i = floor(p);
                vec2 f = fract(p);
                float a = random(i);
                float b = random(i + vec2(1.0, 0.0));
                float c = random(i + vec2(0.0, 1.0));
                float d = random(i + vec2(1.0, 1.0));
                vec2 u = f * f * (3.0 - 2.0 * f);
                return mix(a, b, u.x) + (c - a) * u.y + (d - c) * u.x * u.y;
            }

            float fbm(vec2 p) {
                float total = 0.0;
                float amplitude = 1.0;
                for (int i = 0; i < 6; i++) {
                    total += noise(p) * amplitude;
                    p *= 2.0;
                    amplitude *= 0.5;
                }
                return total;
            }

            void main() {
                vec2 uv = v_uv;
                vec2 pos = (gl_FragCoord.xy / u_resolution.xy) * 2.0 - 1.0;

                float audioEffect = u_audioData * 5.0;
                float distortion = fbm(uv * u_fractalIntensity + audioEffect) * 0.5;
                float glitch = step(0.9, random(uv * u_time * 2.0)) * 0.5;

                vec3 color = vec3(distortion * 0.5 + glitch, distortion * 0.3, distortion * 0.8);
                gl_FragColor = vec4(color, 1.0);
            }
        `;

        function createShader(gl, type, source) {
            const shader = gl.createShader(type);
            gl.shaderSource(shader, source);
            gl.compileShader(shader);
            if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                console.error(gl.getShaderInfoLog(shader));
                gl.deleteShader(shader);
                return null;
            }
            return shader;
        }

        const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexShaderSource);
        const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentShaderSource);
        
        const program = gl.createProgram();
        gl.attachShader(program, vertexShader);
        gl.attachShader(program, fragmentShader);
        gl.linkProgram(program);
        if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
            console.error(gl.getProgramInfoLog(program));
            gl.deleteProgram(program);
            throw new Error("Program failed to link");
        }

        gl.useProgram(program);

        const positionBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
        const positions = [
            -1.0, -1.0,
             1.0, -1.0,
            -1.0,  1.0,
            -1.0,  1.0,
             1.0, -1.0,
             1.0,  1.0
        ];
        gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(positions), gl.STATIC_DRAW);

        const positionAttributeLocation = gl.getAttribLocation(program, "a_position");
        gl.enableVertexAttribArray(positionAttributeLocation);
        gl.vertexAttribPointer(positionAttributeLocation, 2, gl.FLOAT, false, 0, 0);

        const resolutionUniformLocation = gl.getUniformLocation(program, "u_resolution");
        const timeUniformLocation = gl.getUniformLocation(program, "u_time");
        const audioDataUniformLocation = gl.getUniformLocation(program, "u_audioData");
        const fractalIntensityLocation = gl.getUniformLocation(program, "u_fractalIntensity");

        gl.uniform2f(resolutionUniformLocation, canvas.width, canvas.height);

        let time = 0.0;
        let audioData = 0.0;
        let fractalIntensity = 1.0;
        let analyser;

        async function setupAudio() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                const audioContext = new AudioContext();
                const source = audioContext.createMediaStreamSource(stream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                source.connect(analyser);
                getAudioData();
            } catch (err) {
                console.error("Error capturing audio: ", err);
            }
        }

        function getAudioData() {
            requestAnimationFrame(getAudioData);
            if (analyser) {
                const dataArray = new Uint8Array(analyser.frequencyBinCount);
                analyser.getByteFrequencyData(dataArray);
                const average = dataArray.reduce((sum, value) => sum + value, 0) / dataArray.length;
                audioData = average / 128.0;
            }
        }

        setupAudio();

        document.getElementById("fractalIntensity").addEventListener("input", (event) => {
            fractalIntensity = event.target.value;
        });

        function render() {
            time += 0.02;
            gl.uniform1f(timeUniformLocation, time);
            gl.uniform1f(audioDataUniformLocation, audioData);
            gl.uniform1f(fractalIntensityLocation, fractalIntensity);
            
            gl.clear(gl.COLOR_BUFFER_BIT);
            gl.drawArrays(gl.TRIANGLES, 0, 6);

            requestAnimationFrame(render);
        }

        requestAnimationFrame(render);
    </script>
</body>
</html>
