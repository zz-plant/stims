<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>WebGPU Audio Visualizer</title>
    <link rel="stylesheet" href="assets/css/base.css" />
    <style>
      body,
      html {
        background-color: #000;
        display: flex;
        justify-content: center;
        align-items: center;
        height: 100vh;
      }
      canvas {
        width: 100vw;
        height: 100vh;
      }
    </style>
  </head>
  <body>
    <div id="error-message" role="alert" style="display: none; color: #ff0000; background: #fff0f0; text-align: center; padding: 10px;"></div>
    <canvas id="visualizerCanvas"></canvas>
    <script type="module">
      const canvas = document.getElementById('visualizerCanvas');
      const errorMessageElement = document.getElementById('error-message');

      function showError(message) {
        if (errorMessageElement) {
          errorMessageElement.textContent = message;
          errorMessageElement.style.display = 'block';
        }
      }

      function hideError() {
        if (errorMessageElement) {
          errorMessageElement.style.display = 'none';
        }
      }

      async function initializeAudioVisualizer() {
        if (!navigator.gpu) {
          console.error('WebGPU is not supported on this browser.');
          return;
        }

        // Initialize WebGPU
        const adapter = await navigator.gpu.requestAdapter();
        const device = await adapter.requestDevice();
        const context = canvas.getContext('webgpu');
        const format = navigator.gpu.getPreferredCanvasFormat();
        context.configure({ device, format, alphaMode: 'opaque' });

        // Vertex Shader: Pulsating effect
        const vertexShaderCode = `
        @vertex
        fn main(@location(0) position: vec2<f32>, @builtin(instance_index) instanceIndex: u32)
           -> @builtin(position) vec4<f32> {
          let angle = f32(instanceIndex) * 0.1;
          let pos = vec2(cos(angle) * position.x - sin(angle) * position.y, 
                         sin(angle) * position.x + cos(angle) * position.y);
          return vec4<f32>(pos, 0.0, 1.0);
        }
      `;

        // Fragment Shader: Color changes with frequency
        const fragmentShaderCode = `
        @fragment
        fn main(@location(0) frequency: f32, @builtin(instance_index) index: u32) 
                -> @location(0) vec4<f32> {
          let red = abs(sin(frequency + f32(index) * 0.1));
          let green = abs(cos(frequency * 0.5 + f32(index) * 0.15));
          let blue = abs(sin(frequency * 0.7));
          return vec4<f32>(red, green, blue, 1.0);
        }
      `;

        const vertexShaderModule = device.createShaderModule({
          code: vertexShaderCode,
        });
        const fragmentShaderModule = device.createShaderModule({
          code: fragmentShaderCode,
        });

        // Define Shape Data
        const vertices = new Float32Array([-0.1, -0.1, 0.1, -0.1, 0.0, 0.1]);

        const vertexBuffer = device.createBuffer({
          size: vertices.byteLength,
          usage: GPUBufferUsage.VERTEX | GPUBufferUsage.COPY_DST,
          mappedAtCreation: true,
        });
        new Float32Array(vertexBuffer.getMappedRange()).set(vertices);
        vertexBuffer.unmap();

        const pipeline = device.createRenderPipeline({
          layout: 'auto',
          vertex: {
            module: vertexShaderModule,
            entryPoint: 'main',
            buffers: [
              {
                arrayStride: 2 * 4,
                attributes: [
                  { shaderLocation: 0, offset: 0, format: 'float32x2' },
                ],
              },
            ],
          },
          fragment: {
            module: fragmentShaderModule,
            entryPoint: 'main',
            targets: [{ format }],
          },
          primitive: { topology: 'triangle-list' },
        });

        // Audio setup
        let analyser;
        let dataArray;
        try {
          const stream = await navigator.mediaDevices.getUserMedia({
            audio: true,
          });
          const audioContext = new (window.AudioContext ||
            window.webkitAudioContext)();
          analyser = audioContext.createAnalyser();
          const source = audioContext.createMediaStreamSource(stream);
          source.connect(analyser);
          analyser.fftSize = 128;
          dataArray = new Uint8Array(analyser.frequencyBinCount);
          hideError();
        } catch (err) {
          showError('Microphone access was denied. Please allow access and reload.');
          console.error('Error accessing microphone:', err);
          return;
        }

        function frame() {
          analyser.getByteFrequencyData(dataArray);
          const avgFrequency =
            dataArray.reduce((a, b) => a + b) / dataArray.length;
          const normalizedFreq = avgFrequency / 255.0;

          // Draw
          const commandEncoder = device.createCommandEncoder();
          const textureView = context.getCurrentTexture().createView();
          const renderPassDescriptor = {
            colorAttachments: [
              {
                view: textureView,
                clearValue: { r: 0, g: 0, b: 0, a: 1 },
                loadOp: 'clear',
                storeOp: 'store',
              },
            ],
          };

          const passEncoder =
            commandEncoder.beginRenderPass(renderPassDescriptor);
          passEncoder.setPipeline(pipeline);
          passEncoder.setVertexBuffer(0, vertexBuffer);
          for (let i = 0; i < 20; i++) {
            // Render multiple shapes for effect
            passEncoder.draw(3, 1, 0, i);
          }
          passEncoder.end();
          device.queue.submit([commandEncoder.finish()]);

          requestAnimationFrame(frame);
        }

        frame();
      }

      initializeAudioVisualizer().catch(console.error);
    </script>
  </body>
</html>
